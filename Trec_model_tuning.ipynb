{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Finetune Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "344fcb4f81ab9a35"
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## Tune \"all-MiniLM-L6-v2\" using CosineSimilarityLoss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d26ddded8c78db11"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TREC_Dataset\\train_5500.label...\n",
      "Downloading TREC_Dataset\\TREC_10.label...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arun.Tipingiri\\AppData\\Local\\miniconda3\\envs\\gp_7643\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b319147eb38445fc84b9023be6f6ea34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/625 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03970e871fa743a596a22139e822e4de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fine-tuned and saved models/sbert-trec-cosine\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def create_pos_neg_pairs(texts, labels, num_samples=5000):\n",
    "    label_to_texts = {}\n",
    "    for text, label in zip(texts, labels):\n",
    "        label_to_texts.setdefault(label, []).append(text)\n",
    "\n",
    "    train_examples = []\n",
    "    unique_labels = list(label_to_texts.keys())\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        pos_label = random.choice(unique_labels)\n",
    "        neg_label = random.choice([l for l in unique_labels if l != pos_label])\n",
    "\n",
    "        if len(label_to_texts[pos_label]) < 2:\n",
    "            continue  # not enough positives\n",
    "\n",
    "        pos_pair = random.sample(label_to_texts[pos_label], 2)\n",
    "        neg_sample = random.choice(label_to_texts[neg_label])\n",
    "\n",
    "        train_examples.append(InputExample(texts=pos_pair, label=1.0))  # Positive\n",
    "        train_examples.append(InputExample(texts=[pos_pair[0], neg_sample], label=0.0))  # Negative\n",
    "\n",
    "    return train_examples\n",
    "\n",
    "#  Set seed\n",
    "set_seed(42)\n",
    "\n",
    "#  Load TREC dataset\n",
    "from data.trec_data import TrecDataset\n",
    "dataset = TrecDataset()\n",
    "(train_x, train_y), _, _ = dataset.get_splits()\n",
    "\n",
    "#  Create training data\n",
    "train_examples = create_pos_neg_pairs(train_x, train_y, num_samples=5000)\n",
    "train_loader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "#  Load SBERT model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#  Use CosineSimilarityLoss (float labels required)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "#  Fine-tune\n",
    "model.fit(\n",
    "    train_objectives=[(train_loader, train_loss)],\n",
    "    epochs=1,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    optimizer_params={'lr': 2e-5},\n",
    "    max_grad_norm=0.5,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "#  Save the model\n",
    "model.save(\"models/sbert-trec-cosine\")\n",
    "print(\" Fine-tuned and saved models/sbert-trec-cosine\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T13:40:50.699140Z",
     "start_time": "2025-04-17T13:31:35.050310Z"
    }
   },
   "id": "8f9d0dfa6be7575a",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune \"distilbert-base-nli-stsb-mean-tokens\" using CosineSimilarityLoss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2ead7d9717ccc13"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing file: TREC_Dataset\\train_5500.label\n",
      "Found existing file: TREC_Dataset\\TREC_10.label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arun.Tipingiri\\AppData\\Local\\miniconda3\\envs\\gp_7643\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14a78a9f31504530a1739e1fb6eb75e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/625 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9d9d13b67294ce3bbb27dad7d806711"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fine-tuned and saved: distilbert-trec-cosine\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def create_pos_neg_pairs(texts, labels, num_samples=5000):\n",
    "    label_to_texts = {}\n",
    "    for text, label in zip(texts, labels):\n",
    "        label_to_texts.setdefault(label, []).append(text)\n",
    "\n",
    "    train_examples = []\n",
    "    unique_labels = list(label_to_texts.keys())\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        pos_label = random.choice(unique_labels)\n",
    "        neg_label = random.choice([l for l in unique_labels if l != pos_label])\n",
    "\n",
    "        if len(label_to_texts[pos_label]) < 2:\n",
    "            continue\n",
    "\n",
    "        pos_pair = random.sample(label_to_texts[pos_label], 2)\n",
    "        neg_sample = random.choice(label_to_texts[neg_label])\n",
    "\n",
    "        train_examples.append(InputExample(texts=pos_pair, label=1.0))               #  positive\n",
    "        train_examples.append(InputExample(texts=[pos_pair[0], neg_sample], label=0.0))  #  negative\n",
    "\n",
    "    return train_examples\n",
    "\n",
    "#  Set seed\n",
    "set_seed(42)\n",
    "\n",
    "#  Load TREC dataset\n",
    "from data.trec_data import TrecDataset\n",
    "dataset = TrecDataset()\n",
    "(train_x, train_y), _, _ = dataset.get_splits()\n",
    "\n",
    "#  Create training pairs\n",
    "train_examples = create_pos_neg_pairs(train_x, train_y, num_samples=5000)\n",
    "train_loader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "#  Load model\n",
    "model = SentenceTransformer(\"distilbert-base-nli-stsb-mean-tokens\")\n",
    "\n",
    "#  Cosine similarity loss (float labels)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "#  Fine-tune\n",
    "model.fit(\n",
    "    train_objectives=[(train_loader, train_loss)],\n",
    "    epochs=1,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    optimizer_params={'lr': 2e-5},\n",
    "    max_grad_norm=0.5,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "#  Save fine-tuned model\n",
    "model.save(\"models/distilbert-trec-cosine\")\n",
    "print(\" Fine-tuned and saved: distilbert-trec-cosine\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T14:04:20.255020Z",
     "start_time": "2025-04-17T13:41:50.870893Z"
    }
   },
   "id": "f19e23512035c6e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69b18bfd84dd37c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
